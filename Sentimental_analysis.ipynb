{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import urllib\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import requests\n",
    "import textstat\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link = 'https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt'\n",
    "def loading(link):\n",
    "    lst = []\n",
    "    content = urllib.request.urlopen(link)\n",
    "    for line in content:\n",
    "        lst.append(line.decode('utf-8'))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('LoughranMcDonald_MasterDictionary_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dict = {}\n",
    "negative_dict = {}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['Positive'][i] != 0:\n",
    "        positive_dict[df['Word'][i].lower()] = df['Positive'][i]\n",
    "    if df['Negative'][i] != 0:\n",
    "        negative_dict[df['Word'][i].lower()] = df['Negative'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StopWords_Generic.txt', 'r') as file:\n",
    "    stop_words = []\n",
    "    for words in file:\n",
    "        stop_words.append(words)\n",
    "stop_words = [words.strip('\\n').lower() for words in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap this around a function and apply it for entire data\n",
    "\n",
    "def text_preprocessing(lst, stop_words):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    new_list, sentence_length = [], []\n",
    "    for i in lst:\n",
    "        i = i.strip('\\n').strip('\\t')\n",
    "        i = i.replace('\\n', '').replace('\\t', '')\n",
    "        i = ''.join([j.lower() for j in i if j not in string.punctuation])\n",
    "        i = ''.join([j for j in i if not j.isdigit()])\n",
    "        i = i.strip(' ')\n",
    "        i = ' '.join([j for j in i.split()])\n",
    "        i = ' '.join(w for w in nltk.wordpunct_tokenize(i) if w.lower() in words or not w.isalpha())\n",
    "        \n",
    "        sent_len = len(i)\n",
    "        \n",
    "        sentence_length.append(sent_len)\n",
    "\n",
    "        if len(i) >= 1:\n",
    "            new_list.append(i)\n",
    "        \n",
    "    text =  ' '.join(new_list)\n",
    "    cleaned_text  = ' '.join([words for words in text.split() if words not in stop_words])\n",
    "    tokens = word_tokenize(cleaned_text)\n",
    "    \n",
    "    \n",
    "    avg_sentence_len = np.array(sentence_length).sum()/len(sentence_length)\n",
    "\n",
    "    return tokens, text, avg_sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senti_score (polarity_score):\n",
    "    if  polarity_score <= -0.5:\n",
    "        return 'Most_Negative'\n",
    "    elif polarity_score > -0.5 and polarity_score < 0:\n",
    "        return 'Negative'\n",
    "    elif polarity_score == 0:\n",
    "        return 'Neutral'\n",
    "    elif polarity_score > 0 and polarity_score < 0.5:\n",
    "        return 'Positive'\n",
    "    elif polarity_score >= 0.5:\n",
    "        return 'Very_Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(tokens, positive_dict, negative_dict):\n",
    "\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "\n",
    "    for word in tokens:\n",
    "        if word in positive_dict.keys():\n",
    "            positive_score += 1\n",
    "        if word in negative_dict.keys():\n",
    "            negative_score += 1\n",
    "    \n",
    "    polarity_score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score)/ ((len(tokens)) + 0.000001)\n",
    "    sentiment_score = senti_score(polarity_score)\n",
    "    \n",
    "    return positive_score, negative_score, polarity_score,subjectivity_score,sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import textstat\n",
    "def analysis_of_readability(lst, stop_words):\n",
    "    tokens , text, avg_sent_len = text_preprocessing(lst, stop_words)\n",
    "    syllabus_in_text = textstat.syllable_count(text)\n",
    "    words_in_text = textstat.lexicon_count(text, removepunct=True)\n",
    "    sentence_in_text = textstat.sentence_count(text)\n",
    "    complex_words_len = textstat.difficult_words(text)\n",
    "    fog_index = textstat.gunning_fog(text)\n",
    "    \n",
    "    perc_complex_word = (complex_words_len/len(tokens)) * 100 \n",
    "    \n",
    "    avg_words_per_sentence = words_in_text // sentence_in_text\n",
    "    per_complex_words = round((complex_words_len / words_in_text)*100,2)\n",
    "    fog_index = 0.4 * (avg_words_per_sentence + per_complex_words)\n",
    "    \n",
    "    return avg_words_per_sentence, per_complex_words, fog_index , perc_complex_word, words_in_text, avg_sent_len, syllabus_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_results(links, stop_words):\n",
    "    \n",
    "    positive_score, negative_score, polarity_score,subjectivity_score,sentiment_score = [], [], [], [], []\n",
    "    avg_words_per_sentence, per_complex_words, fog_index,  perc_complex_word, words_in_text, avg_sent_len, syllabus_count, word_counts = [], [], [], [], [], [], [], []\n",
    "    \n",
    "    \n",
    "    pre_tag = 'https://www.sec.gov/Archives/'\n",
    "    for i in range(len(links)):\n",
    "        \n",
    "        \n",
    "        link = links[i]\n",
    "        link = os.path.join(pre_tag, link)\n",
    "        lst = loading(link)\n",
    "        tokens,cleaned_text, _ = text_preprocessing(lst, stop_words)\n",
    "        word_count = len(tokens)\n",
    "        pos_score, neg_score, pol_score,sub_score,sent_score = score(tokens, positive_dict, negative_dict)\n",
    "        avg_words, per_complex, fog_idx, perc_complex, words_text, avg_len, syll_cnt = analysis_of_readability(lst, stop_words)\n",
    "        \n",
    "        positive_score.append(pos_score)\n",
    "        negative_score.append(neg_score)\n",
    "        polarity_score.append(pol_score)\n",
    "        subjectivity_score.append(sub_score)\n",
    "        sentiment_score.append(sent_score)\n",
    "        avg_words_per_sentence.append(avg_words)\n",
    "        per_complex_words.append(per_complex)\n",
    "        fog_index.append(fog_idx)\n",
    "        perc_complex_word.append(perc_complex)\n",
    "        words_in_text.append(words_text)\n",
    "        avg_sent_len.append(avg_len)\n",
    "        word_counts.append(word_count)\n",
    "        syllabus_count.append(syll_cnt)\n",
    "        \n",
    "        time.sleep(10)\n",
    "        \n",
    "    \n",
    "    \n",
    "    pos_ser = pd.Series(positive_score)\n",
    "    neg_ser = pd.Series(negative_score)\n",
    "    pol_ser = pd.Series(polarity_score)\n",
    "    sub_ser = pd.Series(subjectivity_score)\n",
    "    sent_ser = pd.Series(sentiment_score)\n",
    "    avg_ser = pd.Series(avg_words_per_sentence)\n",
    "    complex_ser = pd.Series(per_complex_words)\n",
    "    fog_ser = pd.Series(fog_index)\n",
    "    perc_comp_ser = pd.Series(perc_complex_word)\n",
    "    word_text_ser = pd.Series(words_in_text)\n",
    "    avg_len_ser = pd.Series(avg_len)\n",
    "    word_cnt_ser = pd.Series(word_counts)\n",
    "    syll_ser = pd.Series(syllabus_count)\n",
    "        \n",
    "    return pos_ser, neg_ser, pol_ser, sub_ser, sent_ser, avg_ser, complex_ser, fog_ser, perc_comp_ser, word_text_ser, avg_len_ser, word_cnt_ser, syll_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CIK', 'CONAME', 'FYRMO', 'FDATE', 'FORM', 'SECFNAME'], dtype='object')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cik = pd.read_excel('cik_list.xlsx',engine ='openpyxl')\n",
    "cik.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ser, neg_ser, pol_ser, sub_ser, sent_ser, avg_ser, complex_ser, fog_ser, perc_comp_ser, word_text_ser, avg_len_ser, word_cnt_ser, syll_ser = text_results(cik['SECFNAME'][:2], stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'positive_score':pos_ser, 'negative_score': neg_ser, 'polarity_score':pol_ser,'average_sentence_length': avg_len_ser, 'percentage_of_complex_words': perc_comp_ser,\n",
    "                        'fog_index':fog_ser, 'complex_word_count':complex_ser, 'word_count': word_cnt_ser, 'subjectivity_score':sub_ser, 'sentiment_score':sent_ser,\n",
    "                        'syllabus_count':syll_ser})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>percentage_of_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>syllabus_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2191</td>\n",
       "      <td>-0.372807</td>\n",
       "      <td>38.015603</td>\n",
       "      <td>2.745692</td>\n",
       "      <td>56200.548</td>\n",
       "      <td>1.37</td>\n",
       "      <td>70037</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>Negative</td>\n",
       "      <td>224070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>534</td>\n",
       "      <td>1129</td>\n",
       "      <td>-0.357787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.406860</td>\n",
       "      <td>37921.080</td>\n",
       "      <td>1.70</td>\n",
       "      <td>47375</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>Negative</td>\n",
       "      <td>148404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive_score  negative_score  polarity_score  average_sentence_length  \\\n",
       "0            1001            2191       -0.372807                38.015603   \n",
       "1             534            1129       -0.357787                      NaN   \n",
       "\n",
       "   percentage_of_complex_words  fog_index  complex_word_count  word_count  \\\n",
       "0                     2.745692  56200.548                1.37       70037   \n",
       "1                     3.406860  37921.080                1.70       47375   \n",
       "\n",
       "   subjectivity_score sentiment_score  syllabus_count  \n",
       "0            0.045576        Negative          224070  \n",
       "1            0.035103        Negative          148404  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>percentage_of_complex_words</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>syllabus_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2191</td>\n",
       "      <td>-0.372807</td>\n",
       "      <td>38.015603</td>\n",
       "      <td>2.745692</td>\n",
       "      <td>56200.548</td>\n",
       "      <td>1.37</td>\n",
       "      <td>70037</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>Negative</td>\n",
       "      <td>224070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>534</td>\n",
       "      <td>1129</td>\n",
       "      <td>-0.357787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.406860</td>\n",
       "      <td>37921.080</td>\n",
       "      <td>1.70</td>\n",
       "      <td>47375</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>Negative</td>\n",
       "      <td>148404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positive_score  negative_score  polarity_score  average_sentence_length  \\\n",
       "0            1001            2191       -0.372807                38.015603   \n",
       "1             534            1129       -0.357787                      NaN   \n",
       "\n",
       "   percentage_of_complex_words  fog_index  complex_word_count  word_count  \\\n",
       "0                     2.745692  56200.548                1.37       70037   \n",
       "1                     3.406860  37921.080                1.70       47375   \n",
       "\n",
       "   subjectivity_score sentiment_score  syllabus_count  \n",
       "0            0.045576        Negative          224070  \n",
       "1            0.035103        Negative          148404  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_csv = pd.concat([cik,score_df],ignore_index = True,axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199803.0</td>\n",
       "      <td>1998-03-06</td>\n",
       "      <td>10-K405</td>\n",
       "      <td>edgar/data/3662/0000950170-98-000413.txt</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2191.0</td>\n",
       "      <td>-0.372807</td>\n",
       "      <td>38.015603</td>\n",
       "      <td>2.745692</td>\n",
       "      <td>56200.548</td>\n",
       "      <td>1.37</td>\n",
       "      <td>70037.0</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>Negative</td>\n",
       "      <td>224070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199805.0</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>edgar/data/3662/0000950170-98-001001.txt</td>\n",
       "      <td>534.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>-0.357787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.406860</td>\n",
       "      <td>37921.080</td>\n",
       "      <td>1.70</td>\n",
       "      <td>47375.0</td>\n",
       "      <td>0.035103</td>\n",
       "      <td>Negative</td>\n",
       "      <td>148404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199808.0</td>\n",
       "      <td>1998-08-13</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-000783.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>1998-11-12</td>\n",
       "      <td>10-K/A</td>\n",
       "      <td>edgar/data/3662/0000950170-98-002145.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3662.0</td>\n",
       "      <td>SUNBEAM CORP/FL/</td>\n",
       "      <td>199811.0</td>\n",
       "      <td>1998-11-16</td>\n",
       "      <td>NT 10-Q</td>\n",
       "      <td>edgar/data/3662/0000950172-98-001203.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8761</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8762 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                 1         2          3        4   \\\n",
       "0     3662.0  SUNBEAM CORP/FL/  199803.0 1998-03-06  10-K405   \n",
       "1     3662.0  SUNBEAM CORP/FL/  199805.0 1998-05-15     10-Q   \n",
       "2     3662.0  SUNBEAM CORP/FL/  199808.0 1998-08-13  NT 10-Q   \n",
       "3     3662.0  SUNBEAM CORP/FL/  199811.0 1998-11-12   10-K/A   \n",
       "4     3662.0  SUNBEAM CORP/FL/  199811.0 1998-11-16  NT 10-Q   \n",
       "...      ...               ...       ...        ...      ...   \n",
       "8757     NaN               NaN       NaN        NaT      NaN   \n",
       "8758     NaN               NaN       NaN        NaT      NaN   \n",
       "8759     NaN               NaN       NaN        NaT      NaN   \n",
       "8760     NaN               NaN       NaN        NaT      NaN   \n",
       "8761     NaN               NaN       NaN        NaT      NaN   \n",
       "\n",
       "                                            5       6       7         8   \\\n",
       "0     edgar/data/3662/0000950170-98-000413.txt  1001.0  2191.0 -0.372807   \n",
       "1     edgar/data/3662/0000950170-98-001001.txt   534.0  1129.0 -0.357787   \n",
       "2     edgar/data/3662/0000950172-98-000783.txt     NaN     NaN       NaN   \n",
       "3     edgar/data/3662/0000950170-98-002145.txt     NaN     NaN       NaN   \n",
       "4     edgar/data/3662/0000950172-98-001203.txt     NaN     NaN       NaN   \n",
       "...                                        ...     ...     ...       ...   \n",
       "8757                                       NaN     NaN     NaN       NaN   \n",
       "8758                                       NaN     NaN     NaN       NaN   \n",
       "8759                                       NaN     NaN     NaN       NaN   \n",
       "8760                                       NaN     NaN     NaN       NaN   \n",
       "8761                                       NaN     NaN     NaN       NaN   \n",
       "\n",
       "             9         10         11    12       13        14        15  \\\n",
       "0     38.015603  2.745692  56200.548  1.37  70037.0  0.045576  Negative   \n",
       "1           NaN  3.406860  37921.080  1.70  47375.0  0.035103  Negative   \n",
       "2           NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "3           NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "4           NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "...         ...       ...        ...   ...      ...       ...       ...   \n",
       "8757        NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "8758        NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "8759        NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "8760        NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "8761        NaN       NaN        NaN   NaN      NaN       NaN       NaN   \n",
       "\n",
       "            16  \n",
       "0     224070.0  \n",
       "1     148404.0  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "...        ...  \n",
       "8757       NaN  \n",
       "8758       NaN  \n",
       "8759       NaN  \n",
       "8760       NaN  \n",
       "8761       NaN  \n",
       "\n",
       "[8762 rows x 17 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_csv = pd.concat(cik, score_df)\n",
    "# pd.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.read_excel('irregular verbs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = df2['Base Form']\n",
    "#     matches = []\n",
    "#     for match in ls:\n",
    "#     if \"Hello\" in match:\n",
    "#         matches.append(match)\n",
    "\n",
    "# print(matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
